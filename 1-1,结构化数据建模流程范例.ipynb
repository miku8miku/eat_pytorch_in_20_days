{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1084315",
   "metadata": {},
   "source": [
    "# 1-1,ç»“æ„åŒ–æ•°æ®å»ºæ¨¡æµç¨‹èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db18583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e707554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "#æ‰“å°æ—¶é—´\n",
    "def printbar():\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "\n",
    "#macç³»ç»Ÿä¸Špytorchå’Œmatplotlibåœ¨jupyterä¸­åŒæ—¶è·‘éœ€è¦æ›´æ”¹ç¯å¢ƒå˜é‡\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74d1bbf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.10.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.10.0\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting torchkeras==3.2.3\n",
      "  Downloading torchkeras-3.2.3-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from torchkeras==3.2.3) (2.0.1)\n",
      "Collecting accelerate (from torchkeras==3.2.3)\n",
      "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/codespace/.local/lib/python3.10/site-packages (from torchkeras==3.2.3) (2.0.0)\n",
      "Collecting torchmetrics (from torchkeras==3.2.3)\n",
      "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from torchkeras==3.2.3)\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning (from torchkeras==3.2.3)\n",
      "  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.10/site-packages (from accelerate->torchkeras==3.2.3) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from accelerate->torchkeras==3.2.3) (23.1)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.10/site-packages (from accelerate->torchkeras==3.2.3) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /home/codespace/.local/lib/python3.10/site-packages (from accelerate->torchkeras==3.2.3) (6.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch->torchkeras==3.2.3) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchkeras==3.2.3) (67.7.2)\n",
      "Requirement already satisfied: wheel in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchkeras==3.2.3) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/codespace/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->torchkeras==3.2.3) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/codespace/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->torchkeras==3.2.3) (16.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->torchkeras==3.2.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->torchkeras==3.2.3) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->torchkeras==3.2.3) (2023.3)\n",
      "Collecting fsspec[http]>2021.06.0 (from pytorch-lightning->torchkeras==3.2.3)\n",
      "  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lightning-utilities>=0.7.0 (from pytorch-lightning->torchkeras==3.2.3)\n",
      "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning->torchkeras==3.2.3) (2.28.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning->torchkeras==3.2.3)\n",
      "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->torchkeras==3.2.3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch->torchkeras==3.2.3) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch->torchkeras==3.2.3) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->torchkeras==3.2.3) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->torchkeras==3.2.3) (3.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->torchkeras==3.2.3)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->torchkeras==3.2.3)\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->torchkeras==3.2.3)\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->torchkeras==3.2.3)\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->torchkeras==3.2.3)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning->torchkeras==3.2.3) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning->torchkeras==3.2.3) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning->torchkeras==3.2.3) (2022.12.7)\n",
      "Installing collected packages: tqdm, multidict, lightning-utilities, fsspec, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch-lightning, accelerate, torchkeras\n",
      "Successfully installed accelerate-0.19.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 fsspec-2023.5.0 lightning-utilities-0.8.0 multidict-6.0.4 pytorch-lightning-2.0.2 torchkeras-3.2.3 torchmetrics-0.11.4 tqdm-4.65.0 yarl-1.9.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.10.0\n",
    "!pip install torchkeras==3.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c3b159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.4/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__ =  2.0.0+cu117\n",
      "torchkeras.__version__ =  3.2.3\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchkeras \n",
    "print(\"torch.__version__ = \", torch.__version__)\n",
    "print(\"torchkeras.__version__ = \", torchkeras.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6afb823",
   "metadata": {},
   "source": [
    "```\n",
    "torch.__version__ =  1.10.0\n",
    "torchkeras.__version__ =  3.2.3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bd80bf",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=\"red\">\n",
    " \n",
    "å…¬ä¼—å· **ç®—æ³•ç¾é£Ÿå±‹** å›å¤å…³é”®è¯ï¼š**pytorch**ï¼Œ è·å–æœ¬é¡¹ç›®æºç å’Œæ‰€ç”¨æ•°æ®é›†ç™¾åº¦äº‘ç›˜ä¸‹è½½é“¾æ¥ã€‚\n",
    "    \n",
    "</font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a78c0",
   "metadata": {},
   "source": [
    "### ä¸€ï¼Œå‡†å¤‡æ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22985769",
   "metadata": {},
   "source": [
    "titanicæ•°æ®é›†çš„ç›®æ ‡æ˜¯æ ¹æ®ä¹˜å®¢ä¿¡æ¯é¢„æµ‹ä»–ä»¬åœ¨Titanicå·æ’å‡»å†°å±±æ²‰æ²¡åèƒ½å¦ç”Ÿå­˜ã€‚\n",
    "\n",
    "ç»“æ„åŒ–æ•°æ®ä¸€èˆ¬ä¼šä½¿ç”¨Pandasä¸­çš„DataFrameè¿›è¡Œé¢„å¤„ç†ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "\n",
    "dftrain_raw = pd.read_csv('./eat_pytorch_datasets/titanic/train.csv')\n",
    "dftest_raw = pd.read_csv('./eat_pytorch_datasets/titanic/test.csv')\n",
    "dftrain_raw.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d4eadb",
   "metadata": {},
   "source": [
    "![](./data/1-1-æ•°æ®é›†å±•ç¤º.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7edf254",
   "metadata": {},
   "source": [
    "å­—æ®µè¯´æ˜ï¼š\n",
    "\n",
    "* Survived:0ä»£è¡¨æ­»äº¡ï¼Œ1ä»£è¡¨å­˜æ´»ã€yæ ‡ç­¾ã€‘\n",
    "* Pclass:ä¹˜å®¢æ‰€æŒç¥¨ç±»ï¼Œæœ‰ä¸‰ç§å€¼(1,2,3) ã€è½¬æ¢æˆonehotç¼–ç ã€‘\n",
    "* Name:ä¹˜å®¢å§“å ã€èˆå»ã€‘\n",
    "* Sex:ä¹˜å®¢æ€§åˆ« ã€è½¬æ¢æˆboolç‰¹å¾ã€‘\n",
    "* Age:ä¹˜å®¢å¹´é¾„(æœ‰ç¼ºå¤±) ã€æ•°å€¼ç‰¹å¾ï¼Œæ·»åŠ â€œå¹´é¾„æ˜¯å¦ç¼ºå¤±â€ä½œä¸ºè¾…åŠ©ç‰¹å¾ã€‘\n",
    "* SibSp:ä¹˜å®¢å…„å¼Ÿå§å¦¹/é…å¶çš„ä¸ªæ•°(æ•´æ•°å€¼) ã€æ•°å€¼ç‰¹å¾ã€‘\n",
    "* Parch:ä¹˜å®¢çˆ¶æ¯/å­©å­çš„ä¸ªæ•°(æ•´æ•°å€¼)ã€æ•°å€¼ç‰¹å¾ã€‘\n",
    "* Ticket:ç¥¨å·(å­—ç¬¦ä¸²)ã€èˆå»ã€‘\n",
    "* Fare:ä¹˜å®¢æ‰€æŒç¥¨çš„ä»·æ ¼(æµ®ç‚¹æ•°ï¼Œ0-500ä¸ç­‰) ã€æ•°å€¼ç‰¹å¾ã€‘\n",
    "* Cabin:ä¹˜å®¢æ‰€åœ¨èˆ¹èˆ±(æœ‰ç¼ºå¤±) ã€æ·»åŠ â€œæ‰€åœ¨èˆ¹èˆ±æ˜¯å¦ç¼ºå¤±â€ä½œä¸ºè¾…åŠ©ç‰¹å¾ã€‘\n",
    "* Embarked:ä¹˜å®¢ç™»èˆ¹æ¸¯å£:Sã€Cã€Q(æœ‰ç¼ºå¤±)ã€è½¬æ¢æˆonehotç¼–ç ï¼Œå››ç»´åº¦ S,C,Q,nanã€‘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a726f38",
   "metadata": {},
   "source": [
    "åˆ©ç”¨Pandasçš„æ•°æ®å¯è§†åŒ–åŠŸèƒ½æˆ‘ä»¬å¯ä»¥ç®€å•åœ°è¿›è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æEDAï¼ˆExploratory Data Analysisï¼‰ã€‚\n",
    "\n",
    "labelåˆ†å¸ƒæƒ…å†µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e13165",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "ax = dftrain_raw['Survived'].value_counts().plot(kind = 'bar',\n",
    "     figsize = (12,8),fontsize=15,rot = 0)\n",
    "ax.set_ylabel('Counts',fontsize = 15)\n",
    "ax.set_xlabel('Survived',fontsize = 15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20641f47",
   "metadata": {},
   "source": [
    "![](./data/1-1-Labelåˆ†å¸ƒ.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6fa85c",
   "metadata": {},
   "source": [
    "å¹´é¾„åˆ†å¸ƒæƒ…å†µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "ax = dftrain_raw['Age'].plot(kind = 'hist',bins = 20,color= 'purple',\n",
    "                    figsize = (12,8),fontsize=15)\n",
    "\n",
    "ax.set_ylabel('Frequency',fontsize = 15)\n",
    "ax.set_xlabel('Age',fontsize = 15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58763f84",
   "metadata": {},
   "source": [
    "![](./data/1-1-å¹´é¾„åˆ†å¸ƒ.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab6193",
   "metadata": {},
   "source": [
    "å¹´é¾„å’Œlabelçš„ç›¸å…³æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a0979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "ax = dftrain_raw.query('Survived == 0')['Age'].plot(kind = 'density',\n",
    "                      figsize = (12,8),fontsize=15)\n",
    "dftrain_raw.query('Survived == 1')['Age'].plot(kind = 'density',\n",
    "                      figsize = (12,8),fontsize=15)\n",
    "ax.legend(['Survived==0','Survived==1'],fontsize = 12)\n",
    "ax.set_ylabel('Density',fontsize = 15)\n",
    "ax.set_xlabel('Age',fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dab310",
   "metadata": {},
   "source": [
    "![](./data/1-1-å¹´é¾„ç›¸å…³æ€§.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba0563",
   "metadata": {},
   "source": [
    "ä¸‹é¢ä¸ºæ­£å¼çš„æ•°æ®é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28dcead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dfdata):\n",
    "\n",
    "    dfresult= pd.DataFrame()\n",
    "\n",
    "    #Pclass\n",
    "    dfPclass = pd.get_dummies(dfdata['Pclass'])\n",
    "    dfPclass.columns = ['Pclass_' +str(x) for x in dfPclass.columns ]\n",
    "    dfresult = pd.concat([dfresult,dfPclass],axis = 1)\n",
    "\n",
    "    #Sex\n",
    "    dfSex = pd.get_dummies(dfdata['Sex'])\n",
    "    dfresult = pd.concat([dfresult,dfSex],axis = 1)\n",
    "\n",
    "    #Age\n",
    "    dfresult['Age'] = dfdata['Age'].fillna(0)\n",
    "    dfresult['Age_null'] = pd.isna(dfdata['Age']).astype('int32')\n",
    "\n",
    "    #SibSp,Parch,Fare\n",
    "    dfresult['SibSp'] = dfdata['SibSp']\n",
    "    dfresult['Parch'] = dfdata['Parch']\n",
    "    dfresult['Fare'] = dfdata['Fare']\n",
    "\n",
    "    #Carbin\n",
    "    dfresult['Cabin_null'] =  pd.isna(dfdata['Cabin']).astype('int32')\n",
    "\n",
    "    #Embarked\n",
    "    dfEmbarked = pd.get_dummies(dfdata['Embarked'],dummy_na=True)\n",
    "    dfEmbarked.columns = ['Embarked_' + str(x) for x in dfEmbarked.columns]\n",
    "    dfresult = pd.concat([dfresult,dfEmbarked],axis = 1)\n",
    "\n",
    "    return(dfresult)\n",
    "\n",
    "x_train = preprocessing(dftrain_raw).values\n",
    "y_train = dftrain_raw[['Survived']].values\n",
    "\n",
    "x_test = preprocessing(dftest_raw).values\n",
    "y_test = dftest_raw[['Survived']].values\n",
    "\n",
    "print(\"x_train.shape =\", x_train.shape )\n",
    "print(\"x_test.shape =\", x_test.shape )\n",
    "\n",
    "print(\"y_train.shape =\", y_train.shape )\n",
    "print(\"y_test.shape =\", y_test.shape )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d2734",
   "metadata": {},
   "source": [
    "```\n",
    "x_train.shape = (712, 15)\n",
    "x_test.shape = (179, 15)\n",
    "y_train.shape = (712, 1)\n",
    "y_test.shape = (179, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6c6d9",
   "metadata": {},
   "source": [
    "è¿›ä¸€æ­¥ä½¿ç”¨DataLoaderå’ŒTensorDatasetå°è£…æˆå¯ä»¥è¿­ä»£çš„æ•°æ®ç®¡é“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d744935",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(TensorDataset(torch.tensor(x_train).float(),torch.tensor(y_train).float()),\n",
    "                     shuffle = True, batch_size = 8)\n",
    "dl_val = DataLoader(TensorDataset(torch.tensor(x_test).float(),torch.tensor(y_test).float()),\n",
    "                     shuffle = False, batch_size = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec2fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•æ•°æ®ç®¡é“\n",
    "for features,labels in dl_train:\n",
    "    print(features,labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd018d",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[  0.0000,   0.0000,   1.0000,   0.0000,   1.0000,   0.0000,   1.0000,\n",
    "           0.0000,   0.0000,   7.8958,   1.0000,   0.0000,   0.0000,   1.0000,\n",
    "           0.0000],\n",
    "        [  1.0000,   0.0000,   0.0000,   0.0000,   1.0000,   0.0000,   1.0000,\n",
    "           0.0000,   0.0000,  30.5000,   0.0000,   0.0000,   0.0000,   1.0000,\n",
    "           0.0000],\n",
    "        [  1.0000,   0.0000,   0.0000,   1.0000,   0.0000,  31.0000,   0.0000,\n",
    "           1.0000,   0.0000, 113.2750,   0.0000,   1.0000,   0.0000,   0.0000,\n",
    "           0.0000],\n",
    "        [  1.0000,   0.0000,   0.0000,   0.0000,   1.0000,  60.0000,   0.0000,\n",
    "           0.0000,   0.0000,  26.5500,   1.0000,   0.0000,   0.0000,   1.0000,\n",
    "           0.0000],\n",
    "        [  0.0000,   0.0000,   1.0000,   0.0000,   1.0000,  28.0000,   0.0000,\n",
    "           0.0000,   0.0000,  22.5250,   1.0000,   0.0000,   0.0000,   1.0000,\n",
    "           0.0000],\n",
    "        [  0.0000,   0.0000,   1.0000,   0.0000,   1.0000,  32.0000,   0.0000,\n",
    "           0.0000,   0.0000,   8.3625,   1.0000,   0.0000,   0.0000,   1.0000,\n",
    "           0.0000],\n",
    "        [  0.0000,   1.0000,   0.0000,   1.0000,   0.0000,  28.0000,   0.0000,\n",
    "           0.0000,   0.0000,  13.0000,   1.0000,   0.0000,   0.0000,   1.0000,\n",
    "           0.0000],\n",
    "        [  1.0000,   0.0000,   0.0000,   0.0000,   1.0000,  36.0000,   0.0000,\n",
    "           0.0000,   1.0000, 512.3292,   0.0000,   1.0000,   0.0000,   0.0000,\n",
    "           0.0000]]) tensor([[0.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [1.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008e20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25126768",
   "metadata": {},
   "source": [
    "### äºŒï¼Œå®šä¹‰æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a275e98",
   "metadata": {},
   "source": [
    "ä½¿ç”¨Pytorché€šå¸¸æœ‰ä¸‰ç§æ–¹å¼æ„å»ºæ¨¡å‹ï¼šä½¿ç”¨nn.SequentialæŒ‰å±‚é¡ºåºæ„å»ºæ¨¡å‹ï¼Œç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºè‡ªå®šä¹‰æ¨¡å‹ï¼Œç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºæ¨¡å‹å¹¶è¾…åŠ©åº”ç”¨æ¨¡å‹å®¹å™¨è¿›è¡Œå°è£…ã€‚\n",
    "\n",
    "æ­¤å¤„é€‰æ‹©ä½¿ç”¨æœ€ç®€å•çš„nn.Sequentialï¼ŒæŒ‰å±‚é¡ºåºæ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617186ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net():\n",
    "    net = nn.Sequential()\n",
    "    net.add_module(\"linear1\",nn.Linear(15,20))\n",
    "    net.add_module(\"relu1\",nn.ReLU())\n",
    "    net.add_module(\"linear2\",nn.Linear(20,15))\n",
    "    net.add_module(\"relu2\",nn.ReLU())\n",
    "    net.add_module(\"linear3\",nn.Linear(15,1))\n",
    "    return net\n",
    "    \n",
    "net = create_net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdef0374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6761227a",
   "metadata": {},
   "source": [
    "### ä¸‰ï¼Œè®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af89d5af",
   "metadata": {},
   "source": [
    "Pytorché€šå¸¸éœ€è¦ç”¨æˆ·ç¼–å†™è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼Œè®­ç»ƒå¾ªç¯çš„ä»£ç é£æ ¼å› äººè€Œå¼‚ã€‚\n",
    "\n",
    "æœ‰3ç±»å…¸å‹çš„è®­ç»ƒå¾ªç¯ä»£ç é£æ ¼ï¼šè„šæœ¬å½¢å¼è®­ç»ƒå¾ªç¯ï¼Œå‡½æ•°å½¢å¼è®­ç»ƒå¾ªç¯ï¼Œç±»å½¢å¼è®­ç»ƒå¾ªç¯ã€‚\n",
    "\n",
    "æ­¤å¤„ä»‹ç»ä¸€ç§è¾ƒé€šç”¨çš„ä»¿ç…§Kerasé£æ ¼çš„è„šæœ¬å½¢å¼çš„è®­ç»ƒå¾ªç¯ã€‚\n",
    "\n",
    "è¯¥è„šæœ¬å½¢å¼çš„è®­ç»ƒä»£ç ä¸ torchkeras åº“çš„æ ¸å¿ƒä»£ç åŸºæœ¬ä¸€è‡´ã€‚\n",
    "\n",
    "torchkerasè¯¦æƒ…:  https://github.com/lyhue1991/torchkeras \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "from copy import deepcopy\n",
    "from torchkeras.metrics import Accuracy\n",
    "\n",
    "\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(str(info)+\"\\n\")\n",
    "    \n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer= torch.optim.Adam(net.parameters(),lr = 0.01)   \n",
    "metrics_dict = {\"acc\":Accuracy()}\n",
    "\n",
    "epochs = 20 \n",
    "ckpt_path='checkpoint.pt'\n",
    "\n",
    "#early_stoppingç›¸å…³è®¾ç½®\n",
    "monitor=\"val_acc\"\n",
    "patience=5\n",
    "mode=\"max\"\n",
    "\n",
    "history = {}\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    printlog(\"Epoch {0} / {1}\".format(epoch, epochs))\n",
    "\n",
    "    # 1ï¼Œtrain -------------------------------------------------  \n",
    "    net.train()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    \n",
    "    loop = tqdm(enumerate(dl_train), total =len(dl_train))\n",
    "    train_metrics_dict = deepcopy(metrics_dict) \n",
    "    \n",
    "    for i, batch in loop: \n",
    "        \n",
    "        features,labels = batch\n",
    "        #forward\n",
    "        preds = net(features)\n",
    "        loss = loss_fn(preds,labels)\n",
    "        \n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        #metrics\n",
    "        step_metrics = {\"train_\"+name:metric_fn(preds, labels).item() \n",
    "                        for name,metric_fn in train_metrics_dict.items()}\n",
    "        \n",
    "        step_log = dict({\"train_loss\":loss.item()},**step_metrics)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        step+=1\n",
    "        if i!=len(dl_train)-1:\n",
    "            loop.set_postfix(**step_log)\n",
    "        else:\n",
    "            epoch_loss = total_loss/step\n",
    "            epoch_metrics = {\"train_\"+name:metric_fn.compute().item() \n",
    "                             for name,metric_fn in train_metrics_dict.items()}\n",
    "            epoch_log = dict({\"train_loss\":epoch_loss},**epoch_metrics)\n",
    "            loop.set_postfix(**epoch_log)\n",
    "\n",
    "            for name,metric_fn in train_metrics_dict.items():\n",
    "                metric_fn.reset()\n",
    "                \n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "        \n",
    "\n",
    "    # 2ï¼Œvalidate -------------------------------------------------\n",
    "    net.eval()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    loop = tqdm(enumerate(dl_val), total =len(dl_val))\n",
    "    \n",
    "    val_metrics_dict = deepcopy(metrics_dict) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in loop: \n",
    "\n",
    "            features,labels = batch\n",
    "            \n",
    "            #forward\n",
    "            preds = net(features)\n",
    "            loss = loss_fn(preds,labels)\n",
    "\n",
    "            #metrics\n",
    "            step_metrics = {\"val_\"+name:metric_fn(preds, labels).item() \n",
    "                            for name,metric_fn in val_metrics_dict.items()}\n",
    "\n",
    "            step_log = dict({\"val_loss\":loss.item()},**step_metrics)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            step+=1\n",
    "            if i!=len(dl_val)-1:\n",
    "                loop.set_postfix(**step_log)\n",
    "            else:\n",
    "                epoch_loss = (total_loss/step)\n",
    "                epoch_metrics = {\"val_\"+name:metric_fn.compute().item() \n",
    "                                 for name,metric_fn in val_metrics_dict.items()}\n",
    "                epoch_log = dict({\"val_loss\":epoch_loss},**epoch_metrics)\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                for name,metric_fn in val_metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "                    \n",
    "    epoch_log[\"epoch\"] = epoch           \n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "\n",
    "    # 3ï¼Œearly-stopping -------------------------------------------------\n",
    "    arr_scores = history[monitor]\n",
    "    best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n",
    "    if best_score_idx==len(arr_scores)-1:\n",
    "        torch.save(net.state_dict(),ckpt_path)\n",
    "        print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "             arr_scores[best_score_idx]),file=sys.stderr)\n",
    "    if len(arr_scores)-best_score_idx>patience:\n",
    "        print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "            monitor,patience),file=sys.stderr)\n",
    "        break \n",
    "    net.load_state_dict(torch.load(ckpt_path))\n",
    "    \n",
    "dfhistory = pd.DataFrame(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b038d69",
   "metadata": {},
   "source": [
    "```\n",
    "================================================================================2022-07-10 21:55:18\n",
    "Epoch 1 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 192.16it/s, train_acc=0.664, train_loss=0.646]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 252.37it/s, val_acc=0.721, val_loss=0.571]\n",
    "<<<<<< reach best val_acc : 0.7206704020500183 >>>>>>\n",
    "\n",
    "================================================================================2022-07-10 21:55:19\n",
    "Epoch 2 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 212.44it/s, train_acc=0.725, train_loss=0.576]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 183.68it/s, val_acc=0.726, val_loss=0.503]\n",
    "<<<<<< reach best val_acc : 0.7262569665908813 >>>>>>\n",
    "\n",
    "================================================================================2022-07-10 21:55:19\n",
    "Epoch 3 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 128.57it/s, train_acc=0.772, train_loss=0.517]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 195.21it/s, val_acc=0.782, val_loss=0.445]\n",
    "<<<<<< reach best val_acc : 0.7821229100227356 >>>>>>\n",
    "\n",
    "================================================================================2022-07-10 21:55:20\n",
    "Epoch 4 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 139.91it/s, train_acc=0.784, train_loss=0.495]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 281.71it/s, val_acc=0.793, val_loss=0.435]\n",
    "<<<<<< reach best val_acc : 0.7932960987091064 >>>>>>\n",
    "\n",
    "================================================================================2022-07-10 21:55:21\n",
    "Epoch 5 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 216.33it/s, train_acc=0.788, train_loss=0.493]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 246.54it/s, val_acc=0.81, val_loss=0.409]\n",
    "<<<<<< reach best val_acc : 0.8100558519363403 >>>>>>\n",
    "\n",
    "================================================================================2022-07-10 21:55:21\n",
    "Epoch 6 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 191.69it/s, train_acc=0.765, train_loss=0.481]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 251.35it/s, val_acc=0.777, val_loss=0.436]\n",
    "\n",
    "================================================================================2022-07-10 21:55:22\n",
    "Epoch 7 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 192.42it/s, train_acc=0.781, train_loss=0.493]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 241.61it/s, val_acc=0.771, val_loss=0.462]\n",
    "\n",
    "================================================================================2022-07-10 21:55:22\n",
    "Epoch 8 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 211.52it/s, train_acc=0.801, train_loss=0.475]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 263.07it/s, val_acc=0.793, val_loss=0.406]\n",
    "\n",
    "================================================================================2022-07-10 21:55:23\n",
    "Epoch 9 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 199.20it/s, train_acc=0.798, train_loss=0.444]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 265.92it/s, val_acc=0.782, val_loss=0.43]\n",
    "\n",
    "================================================================================2022-07-10 21:55:23\n",
    "Epoch 10 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 193.12it/s, train_acc=0.81, train_loss=0.445] \n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 259.94it/s, val_acc=0.771, val_loss=0.506]\n",
    "<<<<<< val_acc without improvement in 5 epoch, early stopping >>>>>>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ba3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec78a930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70f7f3b3",
   "metadata": {},
   "source": [
    "### å››ï¼Œè¯„ä¼°æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefbce96",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬é¦–å…ˆè¯„ä¼°ä¸€ä¸‹æ¨¡å‹åœ¨è®­ç»ƒé›†å’ŒéªŒè¯é›†ä¸Šçš„æ•ˆæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a731173",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhistory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841b8193",
   "metadata": {},
   "source": [
    "![](./data/1-1-dfhistory.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab56d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric(dfhistory, metric):\n",
    "    train_metrics = dfhistory[\"train_\"+metric]\n",
    "    val_metrics = dfhistory['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b47c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory,\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a685c",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h426f4kjqfj20fy0a9q3a.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdfcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory,\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9263b7b",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h426dvo2upj20fy0a9t92.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1cb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7e80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05c4494b",
   "metadata": {},
   "source": [
    "### äº”ï¼Œä½¿ç”¨æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da16f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#é¢„æµ‹æ¦‚ç‡\n",
    "\n",
    "y_pred_probs = torch.sigmoid(net(torch.tensor(x_test[0:10]).float())).data\n",
    "y_pred_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde97226",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[0.1146],\n",
    "        [0.6517],\n",
    "        [0.4307],\n",
    "        [0.8692],\n",
    "        [0.5542],\n",
    "        [0.7894],\n",
    "        [0.1096],\n",
    "        [0.7125],\n",
    "        [0.6027],\n",
    "        [0.1139]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31cb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#é¢„æµ‹ç±»åˆ«\n",
    "y_pred = torch.where(y_pred_probs>0.5,\n",
    "        torch.ones_like(y_pred_probs),torch.zeros_like(y_pred_probs))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bdfb5",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[0.],\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [0.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6cacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57fe8bba",
   "metadata": {},
   "source": [
    "### å…­ï¼Œä¿å­˜æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb7506",
   "metadata": {},
   "source": [
    "Pytorch æœ‰ä¸¤ç§ä¿å­˜æ¨¡å‹çš„æ–¹å¼ï¼Œéƒ½æ˜¯é€šè¿‡è°ƒç”¨pickleåºåˆ—åŒ–æ–¹æ³•å®ç°çš„ã€‚\n",
    "\n",
    "ç¬¬ä¸€ç§æ–¹æ³•åªä¿å­˜æ¨¡å‹å‚æ•°ã€‚\n",
    "\n",
    "ç¬¬äºŒç§æ–¹æ³•ä¿å­˜å®Œæ•´æ¨¡å‹ã€‚\n",
    "\n",
    "æ¨èä½¿ç”¨ç¬¬ä¸€ç§ï¼Œç¬¬äºŒç§æ–¹æ³•å¯èƒ½åœ¨åˆ‡æ¢è®¾å¤‡å’Œç›®å½•çš„æ—¶å€™å‡ºç°å„ç§é—®é¢˜ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113eb43",
   "metadata": {},
   "source": [
    "**1ï¼Œä¿å­˜æ¨¡å‹å‚æ•°(æ¨è)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6098000",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c5f22",
   "metadata": {},
   "source": [
    "```\n",
    "odict_keys(['linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias', 'linear3.weight', 'linear3.bias'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜æ¨¡å‹å‚æ•°\n",
    "\n",
    "torch.save(net.state_dict(), \"./data/net_parameter.pt\")\n",
    "\n",
    "net_clone = create_net()\n",
    "net_clone.load_state_dict(torch.load(\"./data/net_parameter.pt\"))\n",
    "\n",
    "torch.sigmoid(net_clone.forward(torch.tensor(x_test[0:10]).float())).data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47260e15",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[0.1146],\n",
    "        [0.6517],\n",
    "        [0.4307],\n",
    "        [0.8692],\n",
    "        [0.5542],\n",
    "        [0.7894],\n",
    "        [0.1096],\n",
    "        [0.7125],\n",
    "        [0.6027],\n",
    "        [0.1139]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfbadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bee51ce5",
   "metadata": {},
   "source": [
    "**2ï¼Œä¿å­˜å®Œæ•´æ¨¡å‹(ä¸æ¨è)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c969c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(net, './data/net_model.pt')\n",
    "net_loaded = torch.load('./data/net_model.pt')\n",
    "torch.sigmoid(net_loaded(torch.tensor(x_test[0:10]).float())).data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6ab5e",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[0.1146],\n",
    "        [0.6517],\n",
    "        [0.4307],\n",
    "        [0.8692],\n",
    "        [0.5542],\n",
    "        [0.7894],\n",
    "        [0.1096],\n",
    "        [0.7125],\n",
    "        [0.6027],\n",
    "        [0.1139]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7a2e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52eacb75",
   "metadata": {},
   "source": [
    "**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** \n",
    "\n",
    "å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·\"ç®—æ³•ç¾é£Ÿå±‹\"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚\n",
    "\n",
    "ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚\n",
    "\n",
    "![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdbcc33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
